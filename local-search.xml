<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Pytorch中的Autograd</title>
    <link href="/2022/09/06/Pytorch%E4%B8%AD%E7%9A%84autograd/"/>
    <url>/2022/09/06/Pytorch%E4%B8%AD%E7%9A%84autograd/</url>
    
    <content type="html"><![CDATA[<h2 id="Tensor-Basics"><a href="#Tensor-Basics" class="headerlink" title="Tensor Basics"></a>Tensor Basics</h2><p>在使用Pytorch编写深度学习的代码时，几乎所有模型计算相关的操作都会归结于操作Tensor。其中，Pytorch的自动求导机制（Autograd）是所有神经网络的核心。<br>在使用autograd对Tensor进行自动求导时，需要用到Tensor自带的一些属性，以下为一个Tensor中通常会记录的属性：</p><ul><li><strong><code>data</code></strong>：Tensor中存储的数据信息。调用.data可以只获取原始Tensor的数据信息，也就是如果原始Tensor的<strong><em>requires_grad=True</em></strong>，那么通过调用<strong><em>.data</em></strong>得到的新Tensor的<strong><em>requires_grad=False</em></strong>。⚠️需要注意的是，在Pytorch推出<strong><em>.detach()</em></strong>方法之后，应该尽量使用该方法，因为其增加了报错信息。由于通过<strong><em>.data</em></strong>得到的新Tensor与原始Tensor共享同一块内存空间，所以在某些情况下（backward的时候）是不安全的，而且还不会报错。</li><li><strong><code>requires_grad</code></strong>：将其值设置为True则代表该Tensor需要进行求导，之后对于这个Tensor的所有操作都会被追踪到计算历史记录中。</li><li><strong><code>grad</code></strong>：该Tensor的梯度值。⚠️每次在执行backward操作时，都需要将前一时刻的梯度清零，否则梯度值会一直累加造成错误计算。</li><li><strong><code>grad_fn</code></strong>：这个就是backward函数，用来计算梯度。同时也指示了梯度函数是哪一种类型。只有非叶子结点（结果结点）才会有<strong><em>grad_fn</em></strong>。</li><li><strong><code>is_leaf</code></strong>：简单来讲，我们自己手动创建的Tensor都是叶子结点，而叶子结点之间通过计算得到的中间或最终结果都是结果结点。叶子结点的<strong><em>grad_fn=None</em></strong>。<h2 id="Dynamic-Computational-Graph"><a href="#Dynamic-Computational-Graph" class="headerlink" title="Dynamic Computational Graph"></a>Dynamic Computational Graph</h2>所有需要计算梯度的Tensor与操作它们的函数一起构成了动态计算图（Dynamic Computational Graph），动态计算图展示了从叶子结点到结果结点的完整计算链，沿着这个计算链反向利用链式求导法则即可计算变量的梯度。<br>下面通过一段代码展示一个简单的计算图：</li></ul><figure class="highlight Python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> torch<br>x = torch.tensor(<span class="hljs-number">1</span>, dtype=torch.float32, requires_grad=<span class="hljs-literal">True</span>)<br>y = torch.tensor(<span class="hljs-number">2</span>, dtype=torch.float32)<br>z = x * y<br><span class="hljs-keyword">for</span> name, tensor <span class="hljs-keyword">in</span> zip(<span class="hljs-string">"xyz"</span>, [x, y, z]):<br>    print(<span class="hljs-string">'-------------------------'</span>)<br>    print(<span class="hljs-string">f'<span class="hljs-subst">&#123;name&#125;</span> is: <span class="hljs-subst">&#123;tensor&#125;</span>'</span>)<br>    print(<span class="hljs-string">f'is_leaf of <span class="hljs-subst">&#123;name&#125;</span> is: <span class="hljs-subst">&#123;tensor.is_leaf&#125;</span>'</span>)<br>    print(<span class="hljs-string">f'grad_fn of <span class="hljs-subst">&#123;name&#125;</span> is: <span class="hljs-subst">&#123;tensor.grad_fn&#125;</span>'</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>Output<br>-------------------------<br>x <span class="hljs-keyword">is</span>: <span class="hljs-number">1.0</span><br>is_leaf of x <span class="hljs-keyword">is</span>: <span class="hljs-literal">True</span><br>grad_fn of x <span class="hljs-keyword">is</span>: <span class="hljs-literal">None</span><br>-------------------------<br>y <span class="hljs-keyword">is</span>: <span class="hljs-number">2.0</span><br>is_leaf of y <span class="hljs-keyword">is</span>: <span class="hljs-literal">True</span><br>grad_fn of y <span class="hljs-keyword">is</span>: <span class="hljs-literal">None</span><br>-------------------------<br>z <span class="hljs-keyword">is</span>: <span class="hljs-number">2.0</span><br>is_leaf of z <span class="hljs-keyword">is</span>: <span class="hljs-literal">False</span><br>grad_fn of z <span class="hljs-keyword">is</span>: &lt;MulBackward0 object at <span class="hljs-number">0x7fed879b9550</span>&gt;<br></code></pre></td></tr></table></figure><p>上述代码的计算图如下所示：<br><img src="/img/DCG.png" srcset="/img/loading.gif" alt="DCG"></p><h2 id="Backward"><a href="#Backward" class="headerlink" title="Backward()"></a>Backward()</h2><p>当使用torch.autograd.backward()进行梯度计算时，对于得到的结果结点的数据是标量还是非标量要分情况讨论。</p><h3 id="结果结点是标量"><a href="#结果结点是标量" class="headerlink" title="结果结点是标量"></a>结果结点是标量</h3><h3 id="结果结点非标量"><a href="#结果结点非标量" class="headerlink" title="结果结点非标量"></a>结果结点非标量</h3>]]></content>
    
    
    <categories>
      
      <category>深度学习框架学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Xcode项目中配置OpenMP</title>
    <link href="/2022/01/16/OpenMP%E9%85%8D%E7%BD%AE/"/>
    <url>/2022/01/16/OpenMP%E9%85%8D%E7%BD%AE/</url>
    
    <content type="html"><![CDATA[<h2 id="配置步骤"><a href="#配置步骤" class="headerlink" title="配置步骤"></a>配置步骤</h2><h3 id="利用Homebrew安装llvm"><a href="#利用Homebrew安装llvm" class="headerlink" title="利用Homebrew安装llvm"></a>利用Homebrew安装llvm</h3><p>OpenMP的使用需要依赖于llvm编译框架，所以需要下载并安装llvm。执行命令<code>brew install llvm</code>即可。</p><h3 id="在Xcode中配置OpenMP"><a href="#在Xcode中配置OpenMP" class="headerlink" title="在Xcode中配置OpenMP"></a>在Xcode中配置OpenMP</h3><ol><li>在<strong>User-Defined setting</strong>中新添加一个变量名为<strong>CC</strong>，并将其值设置为<code>/usr/local/opt/llvm/clang</code><br><img src="/img/ompcfg1.png" srcset="/img/loading.gif" alt="User-Defined setting"></li><li>在<strong>Enable Modules</strong>中将其值更改为<strong>No</strong>。<br><img src="/img/ompcfg2.png" srcset="/img/loading.gif" alt="Enable Modules"></li><li>填充<strong>Library Search Paths</strong>选项，填充值为<code>/usr/local/opt/llvm/lib</code>。<br><img src="/img/ompcfg3.png" srcset="/img/loading.gif" alt="Library Search Paths"></li><li>接下来填充<strong>Header Search paths</strong>选项，填充值为<code>/usr/local/opt/llvm/lib/clang/13.0.0/include</code>。<br><img src="/img/ompcfg4.png" srcset="/img/loading.gif" alt="Header Search Paths"></li><li>填充<strong>Other C Flags</strong>选项，填充值为<code>-fopenmp</code>。<br><img src="/img/ompcfg5.png" srcset="/img/loading.gif" alt="Other C Flags"></li><li>在<strong>Build Phases</strong>中将动态库链接进去，在<code>/usr/local/lib</code>中找到<code>libomp.dylib</code>库文件，然后直接拖拽进去即可。<br><img src="/img/ompcfg6.png" srcset="/img/loading.gif" alt="Link Library"></li><li>最后，将<strong>Enable Index-While-Building Functionality</strong>选项勾选为<strong>No</strong>。<br><img src="/img/ompcfg7.png" srcset="/img/loading.gif" alt="Enable Index-While-Building Functionality"></li></ol>]]></content>
    
    
    <categories>
      
      <category>OpenMP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>OpenMP配置</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>TensorFlow中的多维tensor运算（tf.tensordot）</title>
    <link href="/2021/08/16/TensorFlow%E4%B8%AD%E7%9A%84%E5%A4%9A%E7%BB%B4tensor%E8%BF%90%E7%AE%97/"/>
    <url>/2021/08/16/TensorFlow%E4%B8%AD%E7%9A%84%E5%A4%9A%E7%BB%B4tensor%E8%BF%90%E7%AE%97/</url>
    
    <content type="html"><![CDATA[<blockquote><p>本文会重点介绍关于TensorFlow中的tf.tensordot函数，但是在详细介绍这一函数之前，还会对其他矩阵乘法相关的函数进行简要说明。</p></blockquote><p><strong>1. tf.multiply</strong><br>tf.multiply的操作等同于*的操作，即计算两个矩阵的按元素乘法。也就是求两个矩阵的哈达玛积（Hadamard product）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">a = tf.constant([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>], shape=(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>))<br>b = tf.constant([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>], shape=(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>))<br>c = tf.multiply(a, b)<br>print(c)<br>print(c == (a * b))<br></code></pre></td></tr></table></figure><p><img src="/img/tfmultiply.png" srcset="/img/loading.gif" alt="result1"><br><strong>2. tf.matmul</strong><br>tf.matmul即是标准的矩阵运算函数，其要求参与运算的两个矩阵必须满足特定的行列关系。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">a = tf.constant([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>], shape=(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>))<br>b = tf.constant([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>], shape=(<span class="hljs-number">3</span>, <span class="hljs-number">2</span>))<br>c = tf.matmul(a, b)<br>print(c)<br></code></pre></td></tr></table></figure><p><img src="/img/tfmatmul.png" srcset="/img/loading.gif" alt="result2"><br><strong>3. tf.tensordot</strong></p><p><em>函数参数</em>：</p><ul><li><p>a: float32或float64类型的Tensor</p></li><li><p>b: 与a相同类型的Tensor</p></li><li><p>axes: 该参数用来表明a、b张量沿哪些轴进行收缩（收缩成一个轴）。该参数既可以是一个整数N，也可以是两个列表来指明要进行收缩的轴。</p></li><li><p>name: 操作的名称（可选）</p></li></ul><p>接下来通过具体的例子来说明tensordot的操作，尤其是参数axes的含义。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">a = tf.constant([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>], shape=(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>))<br>b = tf.constant([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>], shape=(<span class="hljs-number">3</span>, <span class="hljs-number">2</span>))<br><span class="hljs-comment"># axes=1就表明，对a的最后一维和b的第一维进行收缩，此时就和标准的矩阵乘法是一样的。</span><br>c = tf.tensordot(a, b, axes=<span class="hljs-number">1</span>)<br><span class="hljs-comment"># 当axes传入的是列表时，列表中的值将作为索引，分别指定两个张量按照哪些轴进行收缩。因此axes=[[1], [0]]表示按照a的第1号轴和按照b的第0号轴进行收缩。此时也是和标准的矩阵乘法是一样的。</span><br>d = tf.tensordot(a, b, axes=[[<span class="hljs-number">1</span>], [<span class="hljs-number">0</span>]])<br>print(c)<br></code></pre></td></tr></table></figure><p>接下来是复杂一些的例子。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">a = tf.constant([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>, <span class="hljs-number">10</span>, <br>                 <span class="hljs-number">11</span>, <span class="hljs-number">12</span>, <span class="hljs-number">13</span>, <span class="hljs-number">14</span>, <span class="hljs-number">15</span>, <span class="hljs-number">16</span>, <span class="hljs-number">17</span>, <span class="hljs-number">18</span>, <span class="hljs-number">19</span>, <span class="hljs-number">20</span>, <br>                 <span class="hljs-number">21</span>, <span class="hljs-number">22</span>, <span class="hljs-number">23</span>, <span class="hljs-number">24</span>], shape=[<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>])<br> <br>b = tf.constant([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>, <span class="hljs-number">10</span>, <span class="hljs-number">11</span>, <span class="hljs-number">12</span>], shape=[<span class="hljs-number">4</span>, <span class="hljs-number">3</span>])<br><br>c = tf.tensordot(a, b, axes=<span class="hljs-number">2</span>)<br><span class="hljs-comment"># 对a的后两个轴进行Flatten，此时a.shape=(2, 12)</span><br><span class="hljs-comment"># 对b的前两个轴进行Flatten，此时b.shape=(12,)</span><br><span class="hljs-comment"># 因此最终c.shape=(2,)</span><br>d = tf.tensordot(a, b, axes=[[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>], [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>]])<br><span class="hljs-comment"># 该结果与axes=2是一样的</span><br>print(c)<br></code></pre></td></tr></table></figure><p><img src="/img/tensordot1.png" srcset="/img/loading.gif" alt="result3"></p><p>最后需要强调的一点就是，不管两个按照哪些轴进行收缩，都必须保证两个张量按照指定轴收缩后的纬度值是一样的。</p>]]></content>
    
    
    <categories>
      
      <category>深度学习框架学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>TensorFlow</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>使用TensorBoard可视化函数计算过程</title>
    <link href="/2021/08/02/Tensorboard%E7%BB%98%E5%88%B6%E6%9F%90%E4%B8%80%E5%87%BD%E6%95%B0%E7%9A%84%E6%A8%A1%E5%9E%8B%E5%9B%BE/"/>
    <url>/2021/08/02/Tensorboard%E7%BB%98%E5%88%B6%E6%9F%90%E4%B8%80%E5%87%BD%E6%95%B0%E7%9A%84%E6%A8%A1%E5%9E%8B%E5%9B%BE/</url>
    
    <content type="html"><![CDATA[<blockquote><p>TensorBoard是检查TensorFlow模型的强大工具，开发者可以通过查看模型结构的预览图确保模型的构建符合其预期。TensorFlow2.0之后将Keras也整合到了框架中，开发者可以在利用Keras搭建模型后利用回调函数来记录模型结构。但是本文将重点介绍如何可视化一个函数的计算过程。</p></blockquote><p>TensorFlow<a href="https://tensorflow.google.cn/tensorboard/graphs?hl=zh_cn" target="_blank" rel="noopener">官方文档</a>中指出，可以使用TensorBoard中的<strong>TensorFlow Summary Trace API</strong>记录签名函数从而进行可视化。<br>下面是使用Summary Trace API的步骤：</p><ul><li>使用<code>tf.function</code>定义和注释要进行可视化的函数（tf.function注释后可以将Python计算函数转换为高性能的TensorFlow静态图）</li><li>在函数调用站点之前立即使用<code>tf.summary.trace_on()</code></li><li>通过传递<code>profiler=True</code>将配置文件信息（内存、CPU时间）添加到图中</li><li>使用摘要文件编写器，调用<code>tf.summary.trace_export()</code>保存日志数据</li></ul><p>示例如下所示：</p><figure class="highlight Python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-comment"># 定义和注释要进行可视化的函数</span><br><span class="hljs-meta">@tf.function</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">my_func1</span><span class="hljs-params">(x, y)</span>:</span><br>    <span class="hljs-keyword">return</span> tf.add(x, y)<br><br><span class="hljs-comment"># 设置时间和日志文件存放路径</span><br>time_stamp = datetime.now().strftime(<span class="hljs-string">"%Y%m%d-%H%M%S"</span>)<br>logdir = <span class="hljs-string">'./desktop/logs/%s'</span> %time_stamp<br>graph_writer = tf.summary.create_file_writer(logdir)<br><br><span class="hljs-comment"># 定义数据</span><br>num1 = tf.constant(<span class="hljs-number">1</span>)<br>num2 = tf.constant(<span class="hljs-number">2</span>)<br><br><span class="hljs-comment"># 在调用函数前先执行tf.summary.trace_on()函数</span><br>tf.summary.trace_on(graph=<span class="hljs-literal">True</span>, profiler=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># 调用函数</span><br>result1 = my_func1(num1, num2)<br><br><span class="hljs-comment"># 保存日志数据</span><br><span class="hljs-keyword">with</span> graph_writer.as_default():<br>    tf.summary.trace_export(name=<span class="hljs-string">"my_func_trace"</span>, step=<span class="hljs-number">0</span>, profiler_outdir=logdir)<br></code></pre></td></tr></table></figure><p>最后通过执行如下命令查看可视化结果：</p><figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs zsh">tensorboard --logdir ./desktop/logs<br></code></pre></td></tr></table></figure><p><img src="/img/visionfunc.png" srcset="/img/loading.gif" alt="result"></p>]]></content>
    
    
    <categories>
      
      <category>深度学习框架学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>TensorFlow</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Google Colab上部分操作的记录</title>
    <link href="/2020/05/17/Colab%E6%93%8D%E4%BD%9C%E8%AF%B4%E6%98%8E/"/>
    <url>/2020/05/17/Colab%E6%93%8D%E4%BD%9C%E8%AF%B4%E6%98%8E/</url>
    
    <content type="html"><![CDATA[<h2 id="将谷歌云盘内容拷贝到colab中"><a href="#将谷歌云盘内容拷贝到colab中" class="headerlink" title="将谷歌云盘内容拷贝到colab中"></a>将谷歌云盘内容拷贝到colab中</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> google.colab <span class="hljs-keyword">import</span> drive<br>drive.mount(<span class="hljs-string">'/content/drive'</span>)<br></code></pre></td></tr></table></figure><p>执行完之后，点击出现的链接，然后将验证码填入到输入框中即可。</p><h2 id="创建文件链接"><a href="#创建文件链接" class="headerlink" title="创建文件链接"></a>创建文件链接</h2><p>默认云盘内容都是存在<code>My Drive</code>文件夹下，因此要执行代码时，就要利用<code>cd</code>命令跳转目录。但是<code>cd /content/drive/My\ Drive</code>无论如何都找不到<code>My Drive</code>文件夹，即使加了转译符也不行。所以，将整个文件夹下的内容链接到另一个叫<code>mydrive</code>的文件夹下。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> google.colab <span class="hljs-keyword">import</span> drive<br>drive.mount(<span class="hljs-string">'/content/drive'</span>)<br>!ln -s <span class="hljs-string">"/content/drive/My Drive"</span> <span class="hljs-string">"/content/mydrive"</span><br></code></pre></td></tr></table></figure><p>之后就可以正常跳转目录了。</p><p>其他更多的操作可以参考这篇博客<a href="https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d" target="_blank" rel="noopener">Google Colab Free GPU Tutorial</a></p>]]></content>
    
    
    <categories>
      
      <category>Google Colab</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Colab训练模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MacOS 配置支持OpenGL的OpenCV</title>
    <link href="/2020/04/30/OpenCV%E5%90%AF%E7%94%A8OpenGL/"/>
    <url>/2020/04/30/OpenCV%E5%90%AF%E7%94%A8OpenGL/</url>
    
    <content type="html"><![CDATA[<h2 id="启用OpenCV中的OpenGL支持"><a href="#启用OpenCV中的OpenGL支持" class="headerlink" title="启用OpenCV中的OpenGL支持"></a>启用OpenCV中的OpenGL支持</h2><blockquote><p>最近计算机视觉的作业要弄AR，因此一些3D图形的渲染与绘制就要用到OpenGL。但是Homebrew安装的OepnCV默认是不开启WITH_OPENGL选项的，因此就需要下载源码然后手动安装。</p></blockquote><h3 id="下载源码"><a href="#下载源码" class="headerlink" title="下载源码"></a>下载源码</h3><blockquote><p>这里就听老师的，下载的是OpenCV2.4.13.6版本。</p></blockquote><p>不知为何官网Releases下的源码下载总是下到一半就中断，因此就在官方的Github仓库里下载压缩包。<a href="https://github.com/opencv/opencv/releases?after=3.4.1-cvsdk" target="_blank" rel="noopener">下载链接</a></p><p>下载好源码后将其解压放置在电脑的个人目录下，准备开始CMake。</p><h3 id="下载QT"><a href="#下载QT" class="headerlink" title="下载QT"></a>下载QT</h3><p>MacOS上启用OpenGL支持最坑的一点就是，必须联合QT一起编译才能正确启用OpenGL。因此必须预先下载并安装好QT。可以使用Homebrew安装，不过我是通过官网下载的Qt5。<br><strong><em>P.S. 在网上看了好多博客，然后老师给的代码里的README也说必须要下载Qt4才行。但是我之前已经装好Qt5了，实在不想删掉再弄个Qt4。因此就头铁继续干了。</em></strong></p><h3 id="利用CMake配置编译选项"><a href="#利用CMake配置编译选项" class="headerlink" title="利用CMake配置编译选项"></a>利用CMake配置编译选项</h3><ul><li><p>首先在源码所在的同级目录下新创建一个<code>build</code>文件夹。</p></li><li><p>勾选上WITH_QT和WITH_OPENGL后点击configure。<br><img src="/img/Cmake1.png" srcset="/img/loading.gif" alt="Config Cmake"><br>点完之后会报出几个错误，显示关于Qt5的几个路径无法找到，查了半天终于找到以下解决方法。</p></li><li><p>找到<code>build</code>文件夹下的CMakeCache文件，打开文件并找到所有关于Qt5的代码，将其中的路径替换成如下图所示：<br><img src="/img/Cmake2.png" srcset="/img/loading.gif" alt="CMakeCache"></p></li><li><p>更改完后保存，重新configure，发现之前的错误都没有了，然后点击generate。</p></li></ul><h3 id="在命令行中编译"><a href="#在命令行中编译" class="headerlink" title="在命令行中编译"></a>在命令行中编译</h3><ul><li>跳转到<code>build</code>文件夹所在路径，然后执行<code>sudo make</code>指令。<br>编译的过程中，在编译到highgui模块时，会报错并终止编译。错误信息大致就像以下这样</li></ul><p>error: ‘CODEC_FLAG_GLOBAL_HEADER’ was not declared in this scope</p><p>error: ‘AVFMT_RAWPICTURE’ was not declared in this scope</p><p>error: ‘CODEC_FLAG_GLOBAL_HEADER’ was not declared in this scope</p><p>for target ‘modules/highgui/CMakeFiles/opencv_highgui.dir/src/cap_ffmpeg.cpp.o’ failed<br>make[2]: [modules/highgui/CMakeFiles/opencv_highgui.dir/src/cap_ffmpeg.cpp.o] Error 1</p><p>这是因为FFMPEG与OpenCV的版本产生了冲突，两者是分别开发的，因此在编译本版本的OpenCV时使用的FFMPEG并不是此时使用的这个库。所以想要尝试下载不同版本的FFMPEG来匹配，直到在<a href="https://stackoverflow.com/questions/46884682/error-in-building-opencv-with-ffmpeg" target="_blank" rel="noopener">stackoverflow</a>上看到了一位大佬的解决方法。总结来讲就是将以下这三个宏定义复制到<code>cap_ffmpeg_impl.hpp</code>这个头文件的开头即可。</p><figure class="highlight C++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> AV_CODEC_FLAG_GLOBAL_HEADER (1 &lt;&lt; 22)</span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> CODEC_FLAG_GLOBAL_HEADER AV_CODEC_FLAG_GLOBAL_HEADER</span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">define</span> AVFMT_RAWPICTURE 0x0020</span><br></code></pre></td></tr></table></figure><ul><li>重新执行<code>sudo make</code>指令，之后的编译就都正常进行了</li><li>最后zhi xing<code>sudo make install</code>，所有的头文件和库文件就都安装在<code>/usr/local/include</code>和<code>/usr/local/lib</code>路径下了。编译工作大功告成</li></ul><h3 id="配置Xcode"><a href="#配置Xcode" class="headerlink" title="配置Xcode"></a>配置Xcode</h3><p>与之前配置OpenCV项目一样，唯一需要注意的一点就是在链接库文件进项目里时，不要将<code>cv2.so</code>这个文件链接进去。之前无脑全选链接进去的时候，总是会在编译时报错，后来发现是这个鬼。</p><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><figure class="highlight C++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs C++"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;opencv2/opencv.hpp&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;opencv2/highgui.hpp&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;iostream&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;string&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;OpenGL/gl.h&gt;</span></span><br> <br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> cv;<br><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> <span class="hljs-built_in">std</span>;<br> <br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">onDraw</span><span class="hljs-params">(<span class="hljs-keyword">void</span>* param)</span><br></span>&#123;<br>    glClearColor(<span class="hljs-number">0.0f</span>, <span class="hljs-number">0.0f</span>, <span class="hljs-number">1.0f</span>, <span class="hljs-number">1.0f</span>);<br>    glClear(GL_DEPTH_BUFFER_BIT | GL_COLOR_BUFFER_BIT);<br> <br>    glColor3f(<span class="hljs-number">1.0f</span>, <span class="hljs-number">0.0f</span>, <span class="hljs-number">0.0f</span>);<br>    glRectf(<span class="hljs-number">-0.5f</span>, <span class="hljs-number">-0.5f</span>, <span class="hljs-number">0.5f</span>, <span class="hljs-number">0.5f</span>);<br>    glFlush();<br>&#125;<br> <br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span><br></span>&#123;<br>    <span class="hljs-built_in">string</span> openGLWindowName = <span class="hljs-string">"OpenGLDemo"</span>;<br>    namedWindow(openGLWindowName, WINDOW_OPENGL);<br>    resizeWindow(openGLWindowName, <span class="hljs-number">640</span>, <span class="hljs-number">480</span>);<br>    setOpenGlContext(openGLWindowName);<br>    setOpenGlDrawCallback(openGLWindowName, onDraw, <span class="hljs-literal">NULL</span>);<br> <br>    waitKey(<span class="hljs-number">0</span>);<br>    updateWindow(openGLWindowName);<br>    waitKey(<span class="hljs-number">0</span>);<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>如果能正确编译上述代码，就证明以正确开启openGL支持，并会看到以下结果：</p><p><img src="/img/GLresult.png" srcset="/img/loading.gif" alt="result"></p>]]></content>
    
    
    <categories>
      
      <category>OpenCV</category>
      
    </categories>
    
    
    <tags>
      
      <tag>OpenCV项目相关配置</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Tensorflow升级到2.1.0</title>
    <link href="/2020/04/10/Tensorflow1.4.1%E5%8D%87%E7%BA%A7%E5%88%B02.1.0/"/>
    <url>/2020/04/10/Tensorflow1.4.1%E5%8D%87%E7%BA%A7%E5%88%B02.1.0/</url>
    
    <content type="html"><![CDATA[<h2 id="Tensorflow1-4-1升级到2-1-0"><a href="#Tensorflow1-4-1升级到2-1-0" class="headerlink" title="Tensorflow1.4.1升级到2.1.0"></a>Tensorflow1.4.1升级到2.1.0</h2><blockquote><p>Tensorflow 2.1.0优化了计算图，大大简化了使用流程，使得语法更贴近python的原生语法格式</p></blockquote><h3 id="卸载原有的tensorflow1-4-1版本"><a href="#卸载原有的tensorflow1-4-1版本" class="headerlink" title="卸载原有的tensorflow1.4.1版本"></a>卸载原有的tensorflow1.4.1版本</h3><p>至于为何要卸载而不是直接执行<code>sudo pip install --upgrade tensorflow</code>是因为，执行后使用<code>conda list</code>查看其中的tensorflow版本确实是2.1.0，但是利用<code>print(tf.__version__)</code>打印出来的版本信息依然是1.4.1，而且很多新函数都无法使用。<br>最终执行以下命令即可：</p><figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs zsh">conda activate tensorflow <span class="hljs-comment">#启用tensorflow虚拟环境，在其中管理tensorflow的卸载和安装</span><br>pip uninstall tensorflow<br>pip install tensorflow==2.1.0<br></code></pre></td></tr></table></figure><h3 id="关于新版tensorflow特性的几点说明"><a href="#关于新版tensorflow特性的几点说明" class="headerlink" title="关于新版tensorflow特性的几点说明"></a>关于新版tensorflow特性的几点说明</h3><ul><li>取消了v1版本中关于计算图的定义和执行的区分</li><li>新版中的计算图采用动态计算图和autograph两种方式</li><li>动态计算图，即Eager Execution，每定义一个算子，就会立即执行计算图。因此不需要像老版本一样，创建一个会话session，然后在会话中执行计算图，使得其使用更加贴近python原生语法</li><li>动态计算图的缺点就是效率相较于静态计算图要低一些（老版使用的就是静态计算图）</li><li>autograph使用@tf.function装饰器修饰函数，来将其转化为静态计算图，从而提升效率</li></ul>]]></content>
    
    
    <categories>
      
      <category>机器学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>TensorFlow</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MacOS + Hexo + Github个人博客搭建</title>
    <link href="/2020/03/03/MacOS+Hexo+Github%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"/>
    <url>/2020/03/03/MacOS+Hexo+Github%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/</url>
    
    <content type="html"><![CDATA[<h1 id="MacOS-Hexo-Github个人博客搭建"><a href="#MacOS-Hexo-Github个人博客搭建" class="headerlink" title="MacOS + Hexo + Github个人博客搭建"></a>MacOS + Hexo + Github个人博客搭建</h1><blockquote><p>本篇博客主要用于记录搭建的全部过程，以及其中踩的一些坑</p></blockquote><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>搭建博客之前要先安装<strong>Node.js</strong>和<strong>Git</strong>，可按照一下方式进行安装。</p><h3 id="安装Node-js和Git"><a href="#安装Node-js和Git" class="headerlink" title="安装Node.js和Git"></a>安装Node.js和Git</h3><ul><li>利用Homebrew进行安装，没有Homebrew的自行到<a href="https://brew.sh" target="_blank" rel="noopener">官网</a>，按照指定命令安装。</li><li>输入<strong><code>brew install node</code></strong>开始安装Node.js</li><li>输入<strong><code>brew install git</code></strong>开始安装Git</li></ul><h3 id="检查是否安装成功"><a href="#检查是否安装成功" class="headerlink" title="检查是否安装成功"></a>检查是否安装成功</h3><ul><li>输入<strong><code>node -v</code></strong>和<strong><code>Git --version</code></strong>如果显示相关版本信息，则安装成功</li></ul><h2 id="安装Hexo"><a href="#安装Hexo" class="headerlink" title="安装Hexo"></a>安装Hexo</h2><p>准备工作做好后，开始安装Hexo。<br><strong><code>sudo npm install -g hexo</code></strong><br>⚠️ <em>一定要注意的就是，这里一定进行sudo操作，不然无法安装</em></p><h2 id="本地初始化博客"><a href="#本地初始化博客" class="headerlink" title="本地初始化博客"></a>本地初始化博客</h2><ul><li>首先，在一个你要创建博客的目录下新建一个文件夹。这里我的文件夹叫<strong>MyBlog</strong>，然后进入<strong>MyBlog</strong></li></ul><p><strong><code>cd MyBlog</code></strong>    </p><ul><li>输入一下命令，以进行初始化本地的博客文件。</li></ul><p><strong><code>hexo init</code></strong></p><ul><li>然后安装所需要的环境依赖</li></ul><p><strong><code>sudo npm install</code></strong></p><ul><li>之后依次执行一下两个命令，便可以在<a href="https://localhost:4000" target="_blank" rel="noopener">本地</a>查看自己的博客</li></ul><p><strong><code>hexo g</code></strong><br><strong><code>hexo s</code></strong></p><h2 id="使本地博客关联Github"><a href="#使本地博客关联Github" class="headerlink" title="使本地博客关联Github"></a>使本地博客关联Github</h2><p>这里需要说明的就是，由于Github托管文件资源是免费的，所以这是我这种<strong>穷逼</strong>租不起服务器的绝佳方法，如果你是土豪，以下内容就不用看了。</p><h3 id="Github仓库设置"><a href="#Github仓库设置" class="headerlink" title="Github仓库设置"></a>Github仓库设置</h3><ul><li>在Github上新建一个仓库，然后将仓库取名为<strong>username.github.io</strong>，其中username就是你的Github账户名，并且只能是你的账户名。<br><img src="/img/myGithub.png" srcset="/img/loading.gif" alt="image1"></li><li>然后利用编辑器打开<strong>MyBlog</strong>文件夹下的<em>_config.yml</em>文件，然后将文档最后的<em>deploy</em>修改为以下内容<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-attr">deploy:</span><br><span class="hljs-attr">type:</span> <span class="hljs-string">git</span><br><span class="hljs-attr">repository:</span> <span class="hljs-string">https://github.com/username/username.github.io</span><br><span class="hljs-attr">branch:</span> <span class="hljs-string">master</span><br></code></pre></td></tr></table></figure> 将其中的<em>username</em>替换为自己的Github账户名即可。严格注意大小写。</li><li>依次执行以下命令，生成静态文件并将其上传至Github</li></ul><p><strong><code>hexo g</code></strong><br><strong><code>hexo d</code></strong><br>⚠️ 如果执行<strong><code>hexo d</code></strong>时出现错误，则执行<strong><code>npm install hexo-deployer-git --save</code></strong></p><p>之后，本地的博客就与Github关联上了，之后要更新博客时，只需依次执行<strong><code>hexo clean</code></strong>、<strong><code>hexo g</code></strong>和<strong><code>hexo d</code></strong>即可。</p><h2 id="更换博客主题"><a href="#更换博客主题" class="headerlink" title="更换博客主题"></a>更换博客主题</h2><p>Hexo初始安装时，默认的主题是<strong>landscape</strong>，可以根据自己的喜好自行选择喜欢的主题</p><h3 id="下载主题"><a href="#下载主题" class="headerlink" title="下载主题"></a>下载主题</h3><ul><li>到Hexo的主题页面选择自己感兴趣的主题进行下载。</li><li>然后将下载好的主题文件解压，放到themes文件夹中，与<strong>landscape</strong>同级</li></ul><h3 id="博客配置"><a href="#博客配置" class="headerlink" title="博客配置"></a>博客配置</h3><ul><li>我下载的主题是<strong>Fluid</strong>，这里以其为例。<strong>必要的设置</strong>如下所示：<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-attr">highlight:</span><br><span class="hljs-attr">enable:</span> <span class="hljs-literal">false</span>  <span class="hljs-comment"># 关闭默认的代码高亮</span><br><span class="hljs-attr">theme:</span> <span class="hljs-string">fluid</span>  <span class="hljs-comment"># 指定主题</span><br><span class="hljs-attr">language:</span> <span class="hljs-string">zh-CN</span>  <span class="hljs-comment"># 指定语言，可不改</span><br></code></pre></td></tr></table></figure></li></ul><h3 id="主题配置"><a href="#主题配置" class="headerlink" title="主题配置"></a>主题配置</h3><p>关于主题详细的配置就不在此赘述，献上主题官方的使用<a href="https://hexo.fluid-dev.com/docs/guide/" target="_blank" rel="noopener">指南</a>，非常详细，配置起来也相对简单。</p>]]></content>
    
    
    <categories>
      
      <category>Hexo</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Hexo博客搭建</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>XCode关于OpenCV + OpenCL + OpenMP的配置</title>
    <link href="/2020/03/03/opencv+opencl+openmp/"/>
    <url>/2020/03/03/opencv+opencl+openmp/</url>
    
    <content type="html"><![CDATA[<h2 id="配置项目"><a href="#配置项目" class="headerlink" title="配置项目"></a>配置项目</h2><blockquote><p>OpenCL是CUDA的替代品，能够利用GPU执行OpenCV的图形的大量计算；而OpenMP时开放多核编程语言，本质上还是利用CPU</p></blockquote><h3 id="OpenCV"><a href="#OpenCV" class="headerlink" title="OpenCV"></a>OpenCV</h3><ul><li>利用Homebrew安装opencv（C++）</li></ul><p><strong><code>brew install opencv</code></strong></p><ul><li><p>安装的过程中，brew就已经自动执行cmake将opencv包编译好了，所以所有的动态库文件都在<strong><code>/usr/local/Cellar/opencv/4.2.0_1/lib</code></strong>路径下</p></li><li><p>创建一个XCode项目，选择command line，然后将<strong><code>Search Paths</code></strong>下的两个头文件和库文件搜索路径填好</p><ul><li><strong><code>Header Search Paths = &#39;/usr/local/include/opencv4&#39;</code></strong></li><li><strong><code>Library Search Paths = &#39;/usr/local/Cellar/opencv/4.2.0_1/lib&#39;</code></strong></li></ul></li><li><p>之后就要将动态库文件全部链接进项目中，找到<strong><code>Build Phases</code></strong>，然后将opencv文件夹里的lib中的所有动态库文件添加进去即可。<br>⚠️ 在链接库文件时，<strong>一定要将原本的lib文件夹copy一份</strong>，然后链接这个复制后的文件夹里的库文件！！！</p></li></ul><h3 id="OpenCL"><a href="#OpenCL" class="headerlink" title="OpenCL"></a>OpenCL</h3><p>这里要说明一下，安装的时候一定要注意不同的设备所支持的OpenCL版本，目前所有苹果设备支持的最高版本为1.2。同时Apple内置了OpenCL的包，所以只需要在<strong><code>Build Phases</code></strong>中将OpenCL链接进去就可以。</p><h3 id="OpenMP"><a href="#OpenMP" class="headerlink" title="OpenMP"></a>OpenMP</h3><p>网上暂时还没有详细且有效的配置教程，这里就说一下其中一个教程的做法</p><ul><li>利用Homebrew安装<strong><em>llvm</em></strong></li></ul><p><strong><code>brew install llvm</code></strong></p><ul><li>然后像配置OpenCV一样，将<strong><code>Search Paths</code></strong>下的两个搜索路径填好<ul><li><strong><code>Hearder Search Paths = &#39;/usr/local/Cellar/llvm/9.0.1/lib/clang/9.0.1/include&#39;</code></strong></li><li><strong><code>Library Search Paths = &#39;/usr/local/Cellar/llvm/9.0.1/lib/clang/9.0.1/lib&#39;</code></strong></li></ul></li><li>接下来配置参数<br><img src="/img/otherCFlag.png" srcset="/img/loading.gif" alt="image1"></li><li>然后创建一个名为CC的User变量<br><img src="/img/userDefine.png" srcset="/img/loading.gif" alt="image2"><br><img src="/img/CCUser.png" srcset="/img/loading.gif" alt="image3"></li><li>创建软链接</li></ul><p><strong><code>ln -s /usr/local/opt/llvm/bin/clang /usr/local/bin/clang-omp ln -s /usr/local/opt/llvm/bin/clang++ /usr/local/bin/clang++-omp</code></strong></p><ul><li>全局搜索，找出<strong><code>libiomp5.dylib</code></strong>库文件，然后将其复制并粘贴到<strong><code>/usr/local/lib/libiomp5.dylib</code></strong>路径下，一定要粘贴到这里，不然无法使用</li><li>最后在XCode项目里将这个库文件链接进去理论上就可以了</li></ul><p>⚠️ 但是最后，一顿操作猛如虎，运行的时候报出了一堆错误，OpenMP还是用不了，而且网上也找不到别的详细的教程了，太坑了。</p>]]></content>
    
    
    <categories>
      
      <category>OpenCV</category>
      
    </categories>
    
    
    <tags>
      
      <tag>OpenCV项目相关配置</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
